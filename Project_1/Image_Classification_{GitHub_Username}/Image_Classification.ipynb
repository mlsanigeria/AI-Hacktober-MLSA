{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Classification Starter Notebook\n",
    "\n",
    "Welcome to the Image Classification Starter Notebook for our Hacktoberfest competition! ðŸš€\n",
    "\n",
    "In this notebook, you'll find a ready-to-use Python script that provides a solid foundation for building an image classifier to classify buildings into three classes: Bungalow, Highrise, and Storey buildings.\n",
    "\n",
    "## Getting Started\n",
    "\n",
    "To get started, follow these steps:\n",
    "\n",
    "1. **Clone the Repository**: Begin by cloning this repository to your local machine.\n",
    "\n",
    "2. **Organize Your Data**: Ensure that your image data is organized in the `Data` directory, with subdirectories for each class (`Bungalow`, `Highrise`, `Storey-Building`).\n",
    "\n",
    "3. **Open the Notebook**: Open this notebook in a Jupyter environment.\n",
    "\n",
    "4. **Follow the Code**: The notebook contains commented code that guides you through the process of setting up the data, building and training the model, and evaluating its performance.\n",
    "\n",
    "5. **Experiment and Contribute**: Feel free to experiment with different architectures, hyperparameters, or augmentation techniques. If you come up with improvements, consider contributing them back to the project!\n",
    "\n",
    "## Important Notes\n",
    "\n",
    "- Ensure that you have TensorFlow and related dependencies installed in your environment.\n",
    "- If you encounter any issues or have questions, don't hesitate to reach out. We're here to help!\n",
    "\n",
    "Happy coding, and let's build an amazing image classifier together! \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ssffff\\Desktop\\One for all\\Machine Learning Work\\Hacktoberfest\\AI-Hacktober-MLSA\\Project_1\\Image_Classification_{GitHub_Username}\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "IMAGE_HEIGHT = 400 # The height the image is to be resized to\n",
    "IMAGE_WIDTH = 300 # The width the image is to be resized to\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Define paths for data\n",
    "data_dir = 'Data' # Ensure the name of the folder is set to this.\n",
    "class_names = ['Bungalow', 'Highrise', 'Storey-Building']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement Data Generators and Preprocessing pipeline\n",
    "\n",
    "**This will create an easy preprocessing pipeline and will help load your data in batches**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up data generators for training and testing\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,            # Normalize pixel values to [0,1]\n",
    "    validation_split=0.2       # 20% of data will be used for validation\n",
    ")\n",
    "\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=(IMAGE_HEIGHT, IMAGE_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=(IMAGE_HEIGHT, IMAGE_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model architecture\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(IMAGE_HEIGHT, IMAGE_WIDTH, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(3, activation='softmax')  # 3 classes for building types\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=10,\n",
    "    validation_data=validation_generator\n",
    ")\n",
    "# This part of the code allows you to train the model. You can decide to tweak the number of epochs by experimenting with different values.\n",
    "# Rule of thumb: Avoid using too large epochs, to avoid overfitting.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_loss, test_acc = model.evaluate(validation_generator, verbose=2)\n",
    "print(f'Test accuracy: {test_acc*100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_save_model = 'path_to_save_model'\n",
    "\n",
    "# Save the entire model (including architecture, weights, and optimizer state)\n",
    "model.save(path_to_save_model)\n",
    "\n",
    "# If you only want to save the model architecture and weights (without optimizer state)\n",
    "# Uncomment the following line and comment out the previous 'model.save()' line\n",
    "# model.save(path_to_save_model, save_format='tf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
